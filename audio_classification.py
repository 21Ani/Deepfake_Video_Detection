# -*- coding: utf-8 -*-
"""Audio_Classification.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/13OKFgGSrpdteY_qIiENrZ5YcgQwLFDDf
"""

import torch
from torch import nn
from torch.optim import Adam
import librosa
from torch.utils.data import Dataset,DataLoader
from sklearn.preprocessing import LabelEncoder
import matplotlib.pyplot as plt
import numpy as np
import os
import pandas as pd
import time
from skimage.transform import resize

device="cuda" if torch.cuda.is_available() else "cpu"

import os
import pandas as pd

# Mount Google Drive
from google.colab import drive
drive.mount('/content/drive')

# Path to the data folder
data_path = '/content/drive/MyDrive/data'

# Initialize lists to store file paths and labels
audio_urls = []
labels = []

# Loop through subfolders 'real' and 'fake'
for label in ['real', 'fake']:
    folder_path = os.path.join(data_path, label)
    for filename in os.listdir(folder_path):
        if filename.endswith('.wav'):
            file_path = os.path.join(folder_path, filename)
            audio_urls.append(file_path)
            labels.append(label)

# Create DataFrame
df = pd.DataFrame({
    'url': audio_urls,
    'label': labels
})

# Show the first few rows
print(df.head())

# # Shuffle the DataFrame
# df = df.sample(frac=1).reset_index(drop=True)

# # Show the shuffled DataFrame
# print(df.head())

print(df["label"].unique()) # Changed "Class" to "label"

print(df.iloc[0])

print("URL:", df.iloc[0]['url'])
print("Label:", df.iloc[0]['label'])

print("Data Shape:",df.shape)
print("Class Distribution:",df["label"].value_counts())

plt.figure(figsize=(10, 6))
df['label'].value_counts().plot(kind='bar')
plt.title('Class Distribution')
plt.xlabel('Class')
plt.ylabel('Count')
plt.show()

label_encoder = LabelEncoder()
df["label"]=label_encoder.fit_transform(df['label'])
train=df.sample(frac=0.7,random_state=7)
test=df.drop(train.index)
val=test.sample(frac=0.5,random_state=7)
test=test.drop(val.index)

print("Train Shape:",train.shape)
print("Test Shape:",test.shape)
print("Val Shape:",val.shape)

df

class CustomAudioDataset(Dataset):
    def __init__(self, dataframe):
        self.dataframe = dataframe
        self.labels=torch.Tensor(list(dataframe["label"])).type(torch.LongTensor).to(device)
        self.audios=[torch.tensor(self.get_spectrogram(url)) for url in dataframe['url']] # Changed this line
    def __len__(self): # Corrected indentation
        return len(self.dataframe)
    def __getitem__(self, idx): # Corrected indentation
        img_path=self.dataframe.iloc[idx,0]
        label=torch.Tensor(self.labels[idx]).to(device)
        audio = self.audios[idx].unsqueeze(0).to(device)
        return audio, label
    def get_spectrogram(self,url):
        sr=22050
        duration=10
        img_height=224
        img_width=224
        signal,sr=librosa.load(url,sr=sr,duration=duration)
        spec=librosa.feature.melspectrogram(y=signal,sr=sr,n_fft=2048,hop_length=512,n_mels=128)
        spec_db=librosa.power_to_db(spec,ref=np.max)
        spec_resized=librosa.util.fix_length(spec_db,size=(duration*sr)//512+1)
        spec_resized=resize(spec_resized,(img_height,img_width),anti_aliasing=True)
        return spec_resized

train_dataset=CustomAudioDataset(dataframe=train)
test_dataset=CustomAudioDataset(dataframe=test)
val_dataset=CustomAudioDataset(dataframe=val)

LR=1e-4
batch_size=16
epochs=25

train_loader=DataLoader(train_dataset,batch_size=batch_size,shuffle=True)
test_loader=DataLoader(test_dataset,batch_size=batch_size,shuffle=True)
val_loader=DataLoader(val_dataset,batch_size=batch_size,shuffle=True)

class Net(nn.Module): # Changed nn.module to nn.Module
  def __init__(self):
    super(Net,self).__init__()
    self.conv1=nn.Conv2d(1,16,kernel_size=3,padding=1)
    self.conv2=nn.Conv2d(16,32,kernel_size=3,padding=1)
    self.conv3=nn.Conv2d(32,64,kernel_size=3,padding=1)
    self.pool=nn.MaxPool2d(kernel_size=2,stride=2)
    self.relu=nn.ReLU()
    self.flatten=nn.Flatten()
    # Calculate the correct input size for linear1 dynamically
    self.linear1=nn.Linear(64 * 28 * 28, 4096)  # Adjusted input size
    self.linear2=nn.Linear(4096,1024)
    self.linear3=nn.Linear(1024,512)
    self.output=nn.Linear(512,len(df["label"].unique()))
    self.dropout=nn.Dropout(0.5)
  def forward(self,x):
    x=self.conv1(x)
    x=self.pool(x)
    x=self.conv2(x)
    x=self.pool(x)
    x=self.conv3(x)
    x=self.pool(x)
    x=self.relu(x)
    # Remove the unnecessary x.view and rely on Flatten
    x=self.flatten(x)
    x=self.linear1(x)
    x=self.dropout(x)
    x=self.linear2(x)
    x=self.dropout(x)
    x=self.linear3(x)
    x=self.dropout(x)
    x=self.output(x)
    return x

model=Net().to(device)
print(model)



from torchsummary import summary
summary(model,(1,128,256))

criterion=nn.CrossEntropyLoss()
optimizer=Adam(model.parameters(),lr=LR)

total_loss_train_plot = [] # Empty list to be filled with train loss after each epoch
total_loss_validation_plot = [] # Empty list to be filled with validation loss after each epoch
total_acc_train_plot = [] # Empty list to be filled with train accuracy after each epoch
total_acc_validation_plot = [] # Empty list to be filled with validation accuracy after each epoch

# Assign the value of 'epochs' to 'EPOCHS'
EPOCHS = epochs

for epoch in range(EPOCHS):
  start_time = time.time() # We use this to calculate the time of each epoch, it starts a counter once called
  total_acc_train = 0
  total_loss_train = 0
  total_loss_val = 0
  total_acc_val = 0

  for inputs, labels in train_loader:
    outputs = model(inputs)
    train_loss = criterion(outputs, labels)
    total_loss_train += train_loss.item()
    train_loss.backward()

    train_acc = (torch.argmax(outputs, axis = 1) == labels).sum().item()
    total_acc_train += train_acc
    optimizer.step()
    optimizer.zero_grad()

  with torch.no_grad():
    for inputs, labels in val_loader:
      outputs = model(inputs)
      val_loss = criterion(outputs, labels)
      total_loss_val += val_loss.item()

      val_acc = (torch.argmax(outputs, axis = 1) == labels).sum().item()
      total_acc_val += val_acc
  total_loss_train_plot.append(round(total_loss_train/1000, 4))
  total_loss_validation_plot.append(round(total_loss_val/1000, 4))
  total_acc_train_plot.append(round(total_acc_train/(train_dataset.__len__())*100, 4))
  total_acc_validation_plot.append(round(total_acc_val/(val_dataset.__len__())*100, 4))
  epoch_string = f"""
                  Epoch: {epoch+1}/{EPOCHS},
                  Train Loss: {round(total_loss_train/100, 4)},
                  Train Accuracy: {round((total_acc_train/train_dataset.__len__() * 100), 4)},
                  Validation Loss: {round(total_loss_val/100, 4)},
                  Validation Accuracy: {round((total_acc_val/val_dataset.__len__() * 100), 4)}
                  """
  print(epoch_string)
  print("="*30)

with torch.no_grad():
  total_loss_test = 0
  total_acc_test = 0
  for indx, (input, labels) in enumerate(test_loader):

    prediction = model(input)

    acc = (torch.argmax(prediction, axis = 1) == labels).sum().item()
    total_acc_test += acc

print(f"Accuracy Score is: {round((total_acc_test/test_dataset.__len__())*100, 2)}%")

fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(15, 5))

axs[0].plot(total_loss_train_plot, label='Training Loss')
axs[0].plot(total_loss_validation_plot, label='Validation Loss')
axs[0].set_title('Training and Validation Loss over Epochs')
axs[0].set_xlabel('Epochs')
axs[0].set_ylabel('Loss')
axs[1].set_ylim([0, 2])
axs[0].legend()

axs[1].plot(total_acc_train_plot, label='Training Accuracy')
axs[1].plot(total_acc_validation_plot, label='Validation Accuracy')
axs[1].set_title('Training and Validation Accuracy over Epochs')
axs[1].set_xlabel('Epochs')
axs[1].set_ylabel('Accuracy')
axs[1].set_ylim([0, 100])
axs[1].legend()

plt.tight_layout()

plt.show()

